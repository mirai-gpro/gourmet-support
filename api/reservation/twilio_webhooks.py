import os
import json
import base64
import asyncio
import logging
import uuid
import httpx
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, Request, WebSocket, WebSocketDisconnect
from fastapi.responses import Response
from twilio.twiml.voice_response import VoiceResponse, Start, Stream, Pause
from google.cloud import texttospeech
from google.cloud import speech
import google.generativeai as genai

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/twilio", tags=["twilio"])

# ç’°å¢ƒå¤‰æ•°
BASE_URL = os.environ.get('BASE_URL', 'https://your-app.run.app')
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', '')
TWILIO_ACCOUNT_SID = os.environ.get('TWILIO_ACCOUNT_SID', '')
TWILIO_AUTH_TOKEN = os.environ.get('TWILIO_AUTH_TOKEN', '')

# Google Cloud ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
tts_client = texttospeech.TextToSpeechClient()
stt_client = speech.SpeechClient()

# Gemini åˆæœŸåŒ–
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-2.0-flash')
else:
    gemini_model = None
    logger.warning("[Gemini] GOOGLE_API_KEY ãŒæœªè¨­å®š")

# äºˆç´„æƒ…å ±ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
RESERVATION_INFO = {
    "restaurant_name": "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³å²¡éƒ¨",
    "reserver_name": "å±±ç”°å¤ªéƒ",
    "contact_phone": "090-1234-5678",
    "date": "12æœˆ25æ—¥",
    "day_of_week": "æ—¥æ›œæ—¥",
    "time": "19æ™‚",
    "guests": 4,
    "seat_type": "ãƒ†ãƒ¼ãƒ–ãƒ«å¸­",
    "flexibility": "30åˆ†ç¨‹åº¦ãªã‚‰å‰å¾Œå¯èƒ½",
    "notes": "èª•ç”Ÿæ—¥ã®ãŠç¥ã„"
}

# ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ç®¡ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
active_calls = {}

# éŸ³å£°é€ä¿¡ç”¨ã®ãƒ­ãƒƒã‚¯ï¼ˆé€šè©±ã”ã¨ï¼‰
audio_locks = {}

# éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆaudio_id -> MP3ãƒã‚¤ãƒŠãƒªï¼‰
audio_cache = {}

# å³åº§ã®ç›¸æ§ŒéŸ³å£°ï¼ˆäº‹å‰ç”Ÿæˆï¼‰
acknowledgment_audio = None
quick_hai_audio = None  # çŸ­ã„ç›¸æ§Œã€Œã¯ã„ã€‚ã€
greeting_audio = None  # AIæŒ¨æ‹¶éŸ³å£°ï¼ˆäº‹å‰ç”Ÿæˆï¼‰

# ========================================
# Google Cloud TTS
# ========================================

def synthesize_speech_google(text: str, voice_name: str = "ja-JP-Chirp3-HD-Leda") -> bytes:
    """
    Google Cloud TTS ã§éŸ³å£°ã‚’ç”Ÿæˆ
    Twilioç”¨ã« mulaw 8kHz ã§å‡ºåŠ›
    """
    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="ja-JP",
        name=voice_name
    )

    # Twilio Media Streams ç”¨: mulaw 8kHz
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MULAW,
        sample_rate_hertz=8000
    )

    response = tts_client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    return response.audio_content

def synthesize_speech_mp3(text: str, voice_name: str = "ja-JP-Chirp3-HD-Leda") -> bytes:
    """MP3å½¢å¼ã§éŸ³å£°ç”Ÿæˆï¼ˆ<Play>ç”¨ï¼‰"""
    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="ja-JP",
        name=voice_name
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0
    )

    response = tts_client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    return response.audio_content

def initialize_acknowledgment_audio():
    """å³åº§ã®ç›¸æ§ŒéŸ³å£°ã¨AIæŒ¨æ‹¶éŸ³å£°ã‚’äº‹å‰ç”Ÿæˆ"""
    global acknowledgment_audio, quick_hai_audio, greeting_audio
    try:
        # åˆå›ç”¨ã®ç›¸æ§Œ
        acknowledgment_audio = synthesize_speech_mp3("ã¯ã„ã€ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸã€‚")
        logger.info(f"[Init] åˆå›ç›¸æ§ŒéŸ³å£°ç”Ÿæˆå®Œäº†: {len(acknowledgment_audio)} bytes")

        # 2å›ç›®ä»¥é™ç”¨ã®çŸ­ã„ç›¸æ§Œ
        quick_hai_audio = synthesize_speech_mp3("ã¯ã„ã€‚")
        logger.info(f"[Init] çŸ­ã„ç›¸æ§ŒéŸ³å£°ç”Ÿæˆå®Œäº†: {len(quick_hai_audio)} bytes")

        # AIæŒ¨æ‹¶éŸ³å£°
        greeting_text = f"ãŠå¿™ã—ã„ã¨ã“ã‚æã‚Œå…¥ã‚Šã¾ã™ã€‚{RESERVATION_INFO['restaurant_name']}æ§˜ã¸ã€{RESERVATION_INFO['reserver_name']}æ§˜ã®äºˆç´„ã‚’ãŠé¡˜ã„ã—ãŸãã€ãŠé›»è©±ã—ã¦ãŠã‚Šã¾ã™ã€‚ç§ã¯{RESERVATION_INFO['reserver_name']}æ§˜ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚{RESERVATION_INFO['date']}{RESERVATION_INFO['day_of_week']}ã®{RESERVATION_INFO['time']}ã‹ã‚‰ã€{RESERVATION_INFO['reserver_name']}æ§˜åç¾©ã§{RESERVATION_INFO['guests']}åã€{RESERVATION_INFO['seat_type']}ã§ã€äºˆç´„ã‚’ãŠé¡˜ã„ã§ãã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        greeting_audio = synthesize_speech_mp3(greeting_text)
        logger.info(f"[Init] AIæŒ¨æ‹¶éŸ³å£°ç”Ÿæˆå®Œäº†: {len(greeting_audio)} bytes")
    except Exception as e:
        logger.error(f"[Init] éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ç›¸æ§ŒéŸ³å£°ã‚’ç”Ÿæˆ
initialize_acknowledgment_audio()

# ========================================
# Google Cloud STT (Streaming)
# ========================================

def get_stt_streaming_config():
    """Google Cloud STT ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š"""
    recognition_config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.MULAW,
        sample_rate_hertz=8000,
        language_code="ja-JP",
        enable_automatic_punctuation=True,
        model="phone_call",  # é›»è©±éŸ³å£°ã«æœ€é©åŒ–
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=recognition_config,
        interim_results=True,  # ä¸­é–“çµæœã‚‚å–å¾—
        single_utterance=False,  # é€£ç¶šèªè­˜
    )

    return streaming_config

# ========================================
# Gemini ä¼šè©±
# ========================================

def get_gemini_response(user_input: str, call_sid: str) -> str:
    """Gemini ã§ä¼šè©±å¿œç­”ã‚’ç”Ÿæˆ"""
    if not gemini_model:
        return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

    history = active_calls.get(call_sid, {}).get('transcript', [])
    history_text = "\n".join([f"{h['role']}: {h['text']}" for h in history[-10:]])

    prompt = f"""ã‚ãªãŸã¯ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³äºˆç´„ã®é›»è©±ã‚’ã‹ã‘ã¦ã„ã‚‹äºˆç´„ä»£è¡ŒAIã§ã™ã€‚
ä»¥ä¸‹ã®äºˆç´„æƒ…å ±ã§äºˆç´„ã‚’å–ã£ã¦ãã ã•ã„ã€‚ä¸å¯§ãªæ—¥æœ¬èªã§ç°¡æ½”ã«è©±ã—ã¦ãã ã•ã„ï¼ˆ1-2æ–‡ï¼‰ã€‚

ã€äºˆç´„æƒ…å ±ã€‘
- äºˆç´„è€…å: {RESERVATION_INFO['reserver_name']}
- é€£çµ¡å…ˆ: {RESERVATION_INFO['contact_phone']}
- å¸Œæœ›æ—¥: {RESERVATION_INFO['date']}
- å¸Œæœ›æ™‚é–“: {RESERVATION_INFO['time']}
- äººæ•°: {RESERVATION_INFO['guests']}å
- å¸­ç¨®: {RESERVATION_INFO['seat_type']}
- æ™‚é–“ã®èé€š: {RESERVATION_INFO['flexibility']}
- å‚™è€ƒ: {RESERVATION_INFO['notes']}

ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘
{history_text}

ã€åº—å“¡ã®ç™ºè¨€ã€‘
{user_input}

ã€ã‚ãªãŸã®å¿œç­”ã€‘:"""

    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"[Gemini] ã‚¨ãƒ©ãƒ¼: {e}")
        return "å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"

# ========================================
# Webhook ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ========================================

@router.post("/answer")
async def handle_answer(request: Request):
    """
    TwilioãŒé€šè©±ã«å¿œç­”ã—ãŸæ™‚ã«å‘¼ã°ã‚Œã‚‹
    Media Streams (WebSocket) ã‚’é–‹å§‹ã™ã‚‹
    """
    form_data = await request.form()
    call_sid = form_data.get('CallSid')
    from_number = form_data.get('From')
    to_number = form_data.get('To')

    logger.info(f"[Twilio Answer] CallSid={call_sid}, From={from_number}, To={to_number}")

    # é€šè©±æƒ…å ±ã‚’ä¿å­˜
    active_calls[call_sid] = {
        'call_sid': call_sid,
        'from': from_number,
        'to': to_number,
        'status': 'answered',
        'started_at': datetime.now().isoformat(),
        'transcript': [],
        'is_first_interaction': True  # æœ€åˆã®å¿œç­”ãƒ•ãƒ©ã‚°
    }

    # TwiMLãƒ¬ã‚¹ãƒãƒ³ã‚¹
    response = VoiceResponse()

    # æœ€åˆã®æŒ¨æ‹¶ã¯å†ç”Ÿã›ãšã€åº—å“¡ã®ç™ºè©±ã‚’å¾…ã¤

    # Media Streams (WebSocket) ã‚’é–‹å§‹
    start = Start()
    stream = Stream(
        url=f"wss://{BASE_URL.replace('https://', '').replace('http://', '')}/api/twilio/media-stream",
        track="both_tracks"  # é€å—ä¿¡ä¸¡æ–¹
    )
    stream.parameter(name="call_sid", value=call_sid)
    start.append(stream)
    response.append(start)

    # ä¼šè©±ã‚’ç¶™ç¶šï¼ˆStreamãŒå‡¦ç†ï¼‰
    response.pause(length=120)  # æœ€å¤§2åˆ†

    return Response(
        content=str(response),
        media_type="application/xml"
    )

@router.websocket("/media-stream")
async def handle_media_stream(websocket: WebSocket):
    """
    Twilio Media Streams (WebSocket)

    ä»•æ§˜æ›¸æº–æ‹ :
    åº—å“¡ã®å£° â†’ Twilio Audio Stream â†’ Google STT â†’ ãƒ†ã‚­ã‚¹ãƒˆ
                                                      â†“
                                                  Gemini API
                                                      â†“
    AIã®å£° â† Twilio Audio Stream â† Google TTS â† ãƒ†ã‚­ã‚¹ãƒˆ
    """
    await websocket.accept()
    logger.info("[Media Stream] WebSocketæ¥ç¶šé–‹å§‹")

    call_sid = None
    stream_sid = None
    audio_buffer = []

    # STT ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³
    streaming_config = get_stt_streaming_config()

    try:
        async for message in websocket.iter_text():
            data = json.loads(message)
            event = data.get('event')

            if event == 'start':
                # ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
                stream_sid = data.get('streamSid')
                start_data = data.get('start', {})
                custom_params = start_data.get('customParameters', {})
                call_sid = custom_params.get('call_sid')

                # éŸ³å£°é€ä¿¡ç”¨ãƒ­ãƒƒã‚¯ã‚’åˆæœŸåŒ–
                if call_sid:
                    audio_locks[call_sid] = asyncio.Lock()

                logger.info(f"[Media Stream] é–‹å§‹: streamSid={stream_sid}, callSid={call_sid}")

                # 2.5ç§’çµŒã£ã¦ã‚‚åº—å“¡ãŒè©±ã•ãªã„å ´åˆã€AIã‹ã‚‰æŒ¨æ‹¶ã‚’é–‹å§‹
                if call_sid:
                    asyncio.create_task(fallback_greeting(call_sid, 2.5))

            elif event == 'media':
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡
                media = data.get('media', {})
                payload = media.get('payload')  # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸ mulaw éŸ³å£°
                track = media.get('track')  # inbound or outbound

                # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®æ•°å›ã ã‘trackã‚’ãƒ­ã‚°å‡ºåŠ›
                if len(audio_buffer) < 3:
                    logger.info(f"[Media Stream] å—ä¿¡ track={track}, payload_len={len(payload) if payload else 0}")

                # inboundï¼ˆç›¸æ‰‹ã®å£°ï¼‰ã‚’å‡¦ç†
                # AIéŸ³å£°å†ç”Ÿä¸­ã¯ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if payload and track == 'inbound':
                    # AIéŸ³å£°å†ç”Ÿä¸­ã‹ãƒã‚§ãƒƒã‚¯
                    if call_sid and call_sid in active_calls:
                        is_playing = active_calls[call_sid].get('is_playing_audio', False)
                        if is_playing:
                            # AIéŸ³å£°å†ç”Ÿä¸­ã¯ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã—ãªã„
                            continue

                    # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                    audio_data = base64.b64decode(payload)
                    audio_buffer.append(audio_data)

                    # æœ€å°ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºï¼ˆ0.5ç§’ = 25ãƒãƒ£ãƒ³ã‚¯ï¼‰ã«é”ã—ãŸã‚‰å‡¦ç†é–‹å§‹
                    # VADã¯STTå´ã§åˆ¤å®šã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã®ã¿ã§åˆ¤å®š
                    
                    # å¾©å”±ãƒ¢ãƒ¼ãƒ‰ä¸­ã‹ãƒã‚§ãƒƒã‚¯
                    in_recitation_mode = active_calls.get(call_sid, {}).get('in_recitation_mode', False)

                    # æœ€å°ãƒãƒƒãƒ•ã‚¡ï¼ˆ25ãƒãƒ£ãƒ³ã‚¯ = 0.5ç§’ï¼‰ä»¥ä¸Šã§å‡¦ç†
                    # å¾©å”±ãƒ¢ãƒ¼ãƒ‰ã¯é•·ã‚ï¼ˆ100ãƒãƒ£ãƒ³ã‚¯ = 2ç§’ï¼‰ã«è¨­å®š
                    silence_threshold = 100 if in_recitation_mode else 25
                    max_buffer_size = 250 if in_recitation_mode else 150  # 5ç§’ / 3ç§’
                    
                    # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã§å‡¦ç†é–‹å§‹ã‚’åˆ¤å®šï¼ˆVADã¯STTå´ã§è¡Œã†ï¼‰
                    if len(audio_buffer) >= max_buffer_size:
                        logger.info(f"[Media Stream] ãƒãƒƒãƒ•ã‚¡åˆ°é”: {len(audio_buffer)} chunks")
                        audio_to_process = b''.join(audio_buffer)
                        audio_buffer.clear()
                        # å¾©å”±ãƒ¢ãƒ¼ãƒ‰è§£é™¤
                        if call_sid and active_calls.get(call_sid, {}).get('in_recitation_mode', False):
                            active_calls[call_sid]['in_recitation_mode'] = False
                            logger.info(f"[Recitation Mode] å¾©å”±ãƒ¢ãƒ¼ãƒ‰çµ‚äº†ï¼ˆãƒãƒƒãƒ•ã‚¡åˆ°é”ï¼‰")
                        asyncio.create_task(
                            process_audio_chunk(websocket, stream_sid, call_sid, audio_to_process)
                        )

            elif event == 'mark':
                # ãƒãƒ¼ã‚«ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
                mark_name = data.get('mark', {}).get('name')
                logger.info(f"[Media Stream] Mark: {mark_name}")

            elif event == 'stop':
                # ã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†
                logger.info(f"[Media Stream] çµ‚äº†: streamSid={stream_sid}")
                break

    except WebSocketDisconnect:
        logger.info(f"[Media Stream] åˆ‡æ–­: streamSid={stream_sid}")
    except Exception as e:
        logger.error(f"[Media Stream] ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        # é€šè©±çµ‚äº†å‡¦ç†
        if call_sid and call_sid in active_calls:
            active_calls[call_sid]['status'] = 'completed'
            active_calls[call_sid]['ended_at'] = datetime.now().isoformat()
            logger.info(f"[Media Stream] é€šè©±å®Œäº†: {active_calls[call_sid]}")
        # ãƒ­ãƒƒã‚¯ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if call_sid and call_sid in audio_locks:
            del audio_locks[call_sid]

async def process_audio_chunk(websocket: WebSocket, stream_sid: str, call_sid: str, audio_data: bytes):
    """
    éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
    Google STT â†’ å³ç­”ç›¸æ§Œ â†’ Gemini â†’ Google TTS â†’ Twilioé€ä¿¡
    """
    try:
        logger.info(f"[Process Audio] å‡¦ç†é–‹å§‹: {len(audio_data)} bytes")

        # æœ€åˆã®å¿œç­”ã‹ãƒã‚§ãƒƒã‚¯
        if call_sid and call_sid in active_calls:
            is_first = active_calls[call_sid].get('is_first_interaction', False)
            if is_first:
                logger.info(f"[First Interaction] åº—å“¡ã®ç¬¬ä¸€å£°ã‚’æ¤œçŸ¥ â†’ AIæŒ¨æ‹¶ã‚’é–‹å§‹")
                active_calls[call_sid]['is_first_interaction'] = False

                # äº‹å‰ç”Ÿæˆæ¸ˆã¿ã®AIæŒ¨æ‹¶ã‚’å†ç”Ÿ
                if greeting_audio:
                    greeting_id = str(uuid.uuid4())
                    audio_cache[greeting_id] = greeting_audio

                    # AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                    active_calls[call_sid]['is_playing_audio'] = True

                    # æŒ¨æ‹¶ã‚’å†ç”Ÿ
                    await update_call_with_audio(call_sid, greeting_id)

                    # æ¨å®šæ™‚é–“å¾Œã«ãƒ•ãƒ©ã‚°ã‚’è§£é™¤ï¼ˆç´„30-35ç§’ï¼‰
                    asyncio.create_task(reset_playing_flag(call_sid, 35.0))

                    logger.info(f"[First Interaction] AIæŒ¨æ‹¶å†ç”Ÿå®Œäº†")
                return

        # éŸ³å£°å†ç”Ÿä¸­ã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if call_sid and call_sid in active_calls:
            if active_calls[call_sid].get('is_playing_audio', False):
                logger.info(f"[Process Audio] éŸ³å£°å†ç”Ÿä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {call_sid}")
                return

        # Google Cloud STT ã§éŸ³å£°èªè­˜ï¼ˆéåŒæœŸåŒ–ï¼‰
        audio = speech.RecognitionAudio(content=audio_data)
        
        # ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ’ãƒ³ãƒˆã®è¨­å®š
        phrases = [
            "äºˆç´„", "ç©ºå¸­", "æº€å¸­", "ãŠå–ã‚Šã§ãã¾ã™", "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸ",
            "ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸ", "å°‘ã€…ãŠå¾…ã¡ãã ã•ã„", "ç¢ºèªã„ãŸã—ã¾ã™",
            "ãƒ†ãƒ¼ãƒ–ãƒ«å¸­", "ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å¸­", "å€‹å®¤", "ãŠåå‰", "äººæ•°",
            "æ—¥æ™‚", "æ™‚é–“", "ãŠé›»è©±ç•ªå·"
        ]
        
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.MULAW,
            sample_rate_hertz=8000,
            language_code="ja-JP",
            model="phone_call",
            enable_automatic_punctuation=True,
            speech_contexts=[speech.SpeechContext(phrases=phrases)],
            # VADï¼ˆVoice Activity Detectionï¼‰ã‚’æœ‰åŠ¹åŒ–
            use_enhanced=True,  # é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        )

        # åŒæœŸé–¢æ•°ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œ
        response = await asyncio.to_thread(stt_client.recognize, config=config, audio=audio)
        logger.info(f"[STT] çµæœæ•°: {len(response.results)}")

        if response.results:
            transcript = response.results[0].alternatives[0].transcript
            confidence = response.results[0].alternatives[0].confidence

            logger.info(f"[STT] èªè­˜: '{transcript}' (confidence: {confidence:.2f})")

            # ğŸ”¥ ãƒ‡ãƒãƒƒã‚°: confidence ãƒã‚§ãƒƒã‚¯å‰
            logger.info(f"[DEBUG] confidence={confidence}, é–¾å€¤ãƒã‚§ãƒƒã‚¯: {confidence > 0.5}")

            if transcript and confidence > 0.5:
                logger.info(f"[DEBUG] æ¡ä»¶é€šé: transcript='{transcript}', confidence={confidence}")
                
                # ğŸ”¥ ä¼šè©±å±¥æ­´ã«è¿½åŠ ã™ã‚‹å‰ã«åº—å“¡ã®ç™ºè©±å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                staff_count = sum(1 for item in active_calls.get(call_sid, {}).get('transcript', []) if item['role'] == 'åº—å“¡')
                is_first_response = staff_count == 0  # åº—å“¡ã®1å›ç›®
                
                logger.info(f"[Response Check] åº—å“¡ç™ºè©±å›æ•°={staff_count}, åˆå›={is_first_response}")
                logger.info(f"[DEBUG] acknowledgment_audioå­˜åœ¨: {acknowledgment_audio is not None}")
                logger.info(f"[DEBUG] quick_hai_audioå­˜åœ¨: {quick_hai_audio is not None}")

                # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                if call_sid in active_calls:
                    active_calls[call_sid]['transcript'].append({
                        'role': 'åº—å“¡',
                        'text': transcript,
                        'timestamp': datetime.now().isoformat()
                    })
                    logger.info(f"[DEBUG] å±¥æ­´è¿½åŠ å®Œäº†")

                # å³ç­”ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ã¦ã®ç™ºè©±ã«å¯¾ã—ã¦ç›¸æ§Œã‚’å…¥ã‚Œã‚‹ï¼‰
                quick_audio = None
                quick_delay = 0
                quick_text = ""
                
                if is_first_response and acknowledgment_audio:
                    # åˆå›: ä¸å¯§ãªç›¸æ§Œ
                    quick_audio = acknowledgment_audio
                    quick_delay = 1.5  # ã‚„ã‚„é•·ã‚
                    quick_text = "ã¯ã„ã€ã‹ã—ã“ã¾ã‚Šã¾ã—ãŸã€‚"
                    logger.info(f"[Quick Response] åˆå›å¿œç­” â†’ ã€Œ{quick_text}ã€")
                elif quick_hai_audio:
                    # 2å›ç›®ä»¥é™: çŸ­ã„ç›¸æ§Œ
                    quick_audio = quick_hai_audio
                    quick_delay = 0.6
                    quick_text = "ã¯ã„ã€‚"
                    logger.info(f"[Quick Response] é€šå¸¸å¿œç­” â†’ ã€Œ{quick_text}ã€")
                else:
                    logger.warning(f"[Quick Response] ç›¸æ§ŒéŸ³å£°ãŒåˆ©ç”¨ä¸å¯")

                # å³ç­”éŸ³å£°ã‚’å†ç”Ÿ
                if quick_audio:
                    logger.info(f"[DEBUG] å³ç­”éŸ³å£°å†ç”Ÿé–‹å§‹")
                    quick_id = str(uuid.uuid4())
                    audio_cache[quick_id] = quick_audio
                    
                    # ãƒ•ãƒ©ã‚°ã‚’å…ˆã«è¨­å®š
                    if call_sid in active_calls:
                        active_calls[call_sid]['is_playing_audio'] = True
                        logger.info(f"[Audio Playback] ãƒ•ãƒ©ã‚°è¨­å®š: å³ç­”éŸ³å£° {quick_delay}ç§’")
                    
                    # å³åº§ã«å†ç”Ÿé–‹å§‹
                    await update_call_with_audio(call_sid, quick_id)
                    logger.info(f"[DEBUG] update_call_with_audioå®Œäº†")
                    
                    # å³åº§ã«ãƒ•ãƒ©ã‚°ã‚’è§£é™¤ï¼ˆLLMå‡¦ç†ã‚’å¦¨ã’ãªã„ï¼‰
                    logger.info(f"[Quick Response] å³ç­”å®Œäº†ã€ãƒ•ãƒ©ã‚°è§£é™¤ã—ã¦LLMå‡¦ç†ç¶™ç¶š")
                    if call_sid in active_calls:
                        active_calls[call_sid]['is_playing_audio'] = False
                    
                    # ç›¸æ§Œã®é•·ã•åˆ†ã ã‘å¾…æ©Ÿï¼ˆæ¬¡ã®éŸ³å£°ãŒè¢«ã‚‰ãªã„ã‚ˆã†ã«ï¼‰
                    await asyncio.sleep(quick_delay)
                    logger.info(f"[DEBUG] å¾…æ©Ÿå®Œäº†")
                else:
                    logger.warning(f"[DEBUG] quick_audio ãŒ None ã®ãŸã‚å³ç­”ã‚¹ã‚­ãƒƒãƒ—")

                # å¾©å”±ãƒ¢ãƒ¼ãƒ‰æ¤œçŸ¥
                if "å¾©å”±" in transcript:
                    if call_sid in active_calls:
                        active_calls[call_sid]['in_recitation_mode'] = True
                        logger.info(f"[Recitation Mode] å¾©å”±ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")

                # Gemini ã§å¿œç­”ç”Ÿæˆï¼ˆéåŒæœŸåŒ–ï¼‰
                logger.info(f"[LLM] Geminiå‡¦ç†é–‹å§‹")
                ai_response = await asyncio.to_thread(get_gemini_response, transcript, call_sid)
                logger.info(f"[Gemini] å¿œç­”: {ai_response}")

                # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                if call_sid in active_calls:
                    active_calls[call_sid]['transcript'].append({
                        'role': 'AI',
                        'text': ai_response,
                        'timestamp': datetime.now().isoformat()
                    })

                # Google TTS ã§éŸ³å£°ç”Ÿæˆï¼ˆMP3å½¢å¼ï¼‰
                logger.info(f"[TTS] éŸ³å£°ç”Ÿæˆé–‹å§‹: {len(ai_response)}æ–‡å­—")
                tts_audio = await asyncio.to_thread(synthesize_speech_mp3, ai_response)
                logger.info(f"[TTS] éŸ³å£°ç”Ÿæˆå®Œäº†: {len(tts_audio)} bytes")

                # éŸ³å£°ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                audio_id = str(uuid.uuid4())
                audio_cache[audio_id] = tts_audio
                logger.info(f"[Audio Cache] ä¿å­˜: {audio_id}")

                # éŸ³å£°ã®é•·ã•ã‚’æ¨å®šï¼ˆæ—¥æœ¬èª: 1æ–‡å­—ã‚ãŸã‚Š0.25ç§’ + ãƒãƒƒãƒ•ã‚¡ï¼‰
                estimated_duration = len(ai_response) * 0.25 + 2.0

                # AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                if call_sid in active_calls:
                    active_calls[call_sid]['is_playing_audio'] = True
                    logger.info(f"[Audio Playback] é–‹å§‹ãƒ•ãƒ©ã‚°è¨­å®š: {estimated_duration:.1f}ç§’")

                # Twilio REST API ã§é€šè©±ã‚’æ›´æ–°ã—ã¦éŸ³å£°å†ç”Ÿ
                lock = audio_locks.get(call_sid)
                if lock:
                    async with lock:
                        logger.info(f"[Twilio API] é€šè©±æ›´æ–°é–‹å§‹: {call_sid}")
                        await update_call_with_audio(call_sid, audio_id)
                else:
                    await update_call_with_audio(call_sid, audio_id)

                # æ¨å®šæ™‚é–“å¾Œã«ãƒ•ãƒ©ã‚°ã‚’è§£é™¤
                asyncio.create_task(reset_playing_flag(call_sid, estimated_duration))
            else:
                logger.info(f"[DEBUG] æ¡ä»¶ä¸é€šé: transcript='{transcript}', confidence={confidence}")

    except Exception as e:
        import traceback
        logger.error(f"[Process Audio] ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"[Process Audio] ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")

async def reset_playing_flag(call_sid: str, delay: float):
    """éŸ³å£°å†ç”Ÿå®Œäº†å¾Œã«ãƒ•ãƒ©ã‚°ã‚’è§£é™¤"""
    await asyncio.sleep(delay)
    if call_sid in active_calls:
        active_calls[call_sid]['is_playing_audio'] = False
        logger.info(f"[Audio Playback] çµ‚äº†ãƒ•ãƒ©ã‚°è§£é™¤: {call_sid}")


async def fallback_greeting(call_sid: str, timeout: float):
    """
    ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã«AIã‹ã‚‰æŒ¨æ‹¶ã‚’é–‹å§‹ï¼ˆåº—å“¡ãŒè©±ã•ãªã„å ´åˆï¼‰
    """
    await asyncio.sleep(timeout)

    # ã¾ã æœ€åˆã®å¿œç­”ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if call_sid in active_calls and active_calls[call_sid].get('is_first_interaction', False):
        logger.info(f"[Fallback Greeting] {timeout}ç§’çµŒéã€åº—å“¡ãŒè©±ã•ãªã„ãŸã‚AIã‹ã‚‰æŒ¨æ‹¶ã‚’é–‹å§‹")
        active_calls[call_sid]['is_first_interaction'] = False

        # äº‹å‰ç”Ÿæˆæ¸ˆã¿ã®AIæŒ¨æ‹¶ã‚’å†ç”Ÿ
        if greeting_audio:
            greeting_id = str(uuid.uuid4())
            audio_cache[greeting_id] = greeting_audio

            # AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
            active_calls[call_sid]['is_playing_audio'] = True

            # æŒ¨æ‹¶ã‚’å†ç”Ÿ
            await update_call_with_audio(call_sid, greeting_id)

            # æ¨å®šæ™‚é–“å¾Œã«ãƒ•ãƒ©ã‚°ã‚’è§£é™¤ï¼ˆç´„30-35ç§’ï¼‰
            asyncio.create_task(reset_playing_flag(call_sid, 35.0))

            logger.info(f"[Fallback Greeting] AIæŒ¨æ‹¶å†ç”Ÿå®Œäº†")


async def update_call_with_audio(call_sid: str, audio_id: str):
    """
    Twilio REST API ã‚’ä½¿ã£ã¦é€šè©±ã‚’æ›´æ–°ã—ã€éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹
    """
    if not TWILIO_ACCOUNT_SID or not TWILIO_AUTH_TOKEN:
        logger.error("[Twilio API] èªè¨¼æƒ…å ±ãŒæœªè¨­å®š")
        return

    # TwiML URL ã‚’ç”Ÿæˆ
    twiml_url = f"{BASE_URL}/api/twilio/play-audio/{audio_id}"
    logger.info(f"[Twilio API] TwiML URL: {twiml_url}")

    # Twilio REST API ã§é€šè©±ã‚’æ›´æ–°
    url = f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_ACCOUNT_SID}/Calls/{call_sid}.json"

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                url,
                auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN),
                data={"Url": twiml_url}
            )
            if response.status_code == 200:
                logger.info(f"[Twilio API] é€šè©±æ›´æ–°æˆåŠŸ: {call_sid}")
            else:
                logger.error(f"[Twilio API] é€šè©±æ›´æ–°å¤±æ•—: {response.status_code} - {response.text}")
    except Exception as e:
        logger.error(f"[Twilio API] ã‚¨ãƒ©ãƒ¼: {e}")

@router.post("/status")
async def handle_status(request: Request):
    """é€šè©±ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°"""
    form_data = await request.form()
    call_sid = form_data.get('CallSid')
    call_status = form_data.get('CallStatus')
    call_duration = form_data.get('CallDuration')

    logger.info(f"[Twilio Status] CallSid={call_sid}, Status={call_status}, Duration={call_duration}")

    if call_sid in active_calls:
        active_calls[call_sid]['status'] = call_status
        if call_duration:
            active_calls[call_sid]['duration'] = call_duration

        if call_status in ['completed', 'failed', 'busy', 'no-answer']:
            active_calls[call_sid]['ended_at'] = datetime.now().isoformat()

    return Response(status_code=200)

@router.get("/audio/dynamic")
async def get_dynamic_audio(text: str = ""):
    """å‹•çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆï¼ˆMP3å½¢å¼ï¼‰"""
    if not text:
        return Response(status_code=400)

    try:
        from urllib.parse import unquote
        text = unquote(text)

        audio_content = synthesize_speech_mp3(text)
        logger.info(f"[Google TTS] å‹•çš„éŸ³å£°ç”Ÿæˆ: {len(text)}æ–‡å­— â†’ {len(audio_content)} bytes")

        return Response(
            content=audio_content,
            media_type="audio/mpeg"
        )
    except Exception as e:
        logger.error(f"[Google TTS] ã‚¨ãƒ©ãƒ¼: {e}")
        return Response(status_code=500)

@router.post("/play-audio/{audio_id}")
async def play_audio_twiml(audio_id: str, request: Request):
    """
    éŸ³å£°ã‚’å†ç”Ÿã—ã¦Media Streamã‚’å†é–‹ã™ã‚‹TwiML
    Twilio REST API ã‹ã‚‰å‘¼ã°ã‚Œã‚‹
    """
    form_data = await request.form()
    call_sid = form_data.get('CallSid')
    logger.info(f"[Play Audio] TwiMLç”Ÿæˆ: audio_id={audio_id}, call_sid={call_sid}")

    response = VoiceResponse()

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰éŸ³å£°ãŒã‚ã‚‹ã‹ç¢ºèª
    if audio_id in audio_cache:
        # éŸ³å£°ã‚’å†ç”Ÿ
        audio_url = f"{BASE_URL}/api/twilio/audio/{audio_id}"
        response.play(audio_url)
        logger.info(f"[Play Audio] éŸ³å£°å†ç”Ÿ: {audio_url}")
    else:
        logger.warning(f"[Play Audio] éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—: {audio_id}")

    # Media Streamã‚’å†é–‹
    start = Start()
    stream = Stream(
        url=f"wss://{BASE_URL.replace('https://', '').replace('http://', '')}/api/twilio/media-stream",
        track="both_tracks"
    )
    if call_sid:
        stream.parameter(name="call_sid", value=call_sid)
    start.append(stream)
    response.append(start)

    # é€šè©±ã‚’ç¶™ç¶š
    response.pause(length=120)

    return Response(
        content=str(response),
        media_type="application/xml"
    )

@router.get("/audio/{audio_id}")
async def get_cached_audio(audio_id: str):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸéŸ³å£°ã‚’è¿”ã™"""
    if audio_id in audio_cache:
        audio_content = audio_cache[audio_id]
        # ä½¿ç”¨å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
        del audio_cache[audio_id]
        logger.info(f"[Audio Cache] å–å¾—ãƒ»å‰Šé™¤: {audio_id}, {len(audio_content)} bytes")
        return Response(
            content=audio_content,
            media_type="audio/mpeg"
        )
    else:
        logger.warning(f"[Audio Cache] è¦‹ã¤ã‹ã‚‰ãªã„: {audio_id}")
        return Response(status_code=404)

@router.get("/test")
async def test_endpoint():
    """Webhookç–é€šç¢ºèªç”¨"""
    return {
        "status": "ok",
        "message": "Twilio webhook endpoint is ready (HTTP Audio Playback)",
        "active_calls": len(active_calls),
        "audio_cache_size": len(audio_cache),
        "architecture": {
            "stt": "Google Cloud Speech-to-Text",
            "llm": "Gemini 2.0 Flash",
            "tts": "Google Cloud Text-to-Speech",
            "audio_playback": "HTTP via Twilio REST API"
        }
    }

@router.get("/calls")
async def get_active_calls():
    """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªé€šè©±ä¸€è¦§ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    return {
        "calls": list(active_calls.values())
    }
